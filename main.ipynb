{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-09T04:18:53.092174Z",
     "end_time": "2023-04-09T04:18:53.096167Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8l summary (fused): 268 layers, 43668288 parameters, 0 gradients, 165.2 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8l.pt')\n",
    "model.to(device='cuda')\n",
    "model.fuse()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T04:18:55.012231Z",
     "end_time": "2023-04-09T04:18:55.858549Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 3 potted plants, 61.5ms\n",
      "Speed: 0.0ms preprocess, 61.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3 potted plants, 58.0ms\n",
      "Speed: 1.0ms preprocess, 58.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 3 potted plants, 55.9ms\n",
      "Speed: 1.0ms preprocess, 55.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 2 potted plants, 55.3ms\n",
      "Speed: 1.0ms preprocess, 55.3ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 2 potted plants, 56.0ms\n",
      "Speed: 1.0ms preprocess, 56.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 2 potted plants, 54.8ms\n",
      "Speed: 0.0ms preprocess, 54.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 2 potted plants, 52.2ms\n",
      "Speed: 0.0ms preprocess, 52.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 cat, 1 dog, 2 potted plants, 56.7ms\n",
      "Speed: 0.0ms preprocess, 56.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 1 potted plant, 51.4ms\n",
      "Speed: 0.0ms preprocess, 51.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 2 potted plants, 54.5ms\n",
      "Speed: 1.0ms preprocess, 54.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 2 potted plants, 54.5ms\n",
      "Speed: 0.0ms preprocess, 54.5ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 potted plants, 54.3ms\n",
      "Speed: 1.0ms preprocess, 54.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 potted plants, 51.9ms\n",
      "Speed: 1.0ms preprocess, 51.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 potted plants, 56.1ms\n",
      "Speed: 1.0ms preprocess, 56.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 baseball glove, 1 potted plant, 55.7ms\n",
      "Speed: 1.0ms preprocess, 55.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 potted plant, 54.2ms\n",
      "Speed: 0.0ms preprocess, 54.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 potted plant, 55.2ms\n",
      "Speed: 1.0ms preprocess, 55.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 1 potted plant, 56.2ms\n",
      "Speed: 1.0ms preprocess, 56.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 dog, 1 potted plant, 50.6ms\n",
      "Speed: 0.0ms preprocess, 50.6ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 potted plant, 56.6ms\n",
      "Speed: 1.0ms preprocess, 56.6ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 fire hydrant, 1 potted plant, 51.1ms\n",
      "Speed: 0.0ms preprocess, 51.1ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 potted plant, 56.7ms\n",
      "Speed: 0.0ms preprocess, 56.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cats, 1 potted plant, 52.6ms\n",
      "Speed: 0.0ms preprocess, 52.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cats, 1 potted plant, 56.0ms\n",
      "Speed: 0.0ms preprocess, 56.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cat, 1 dog, 1 potted plant, 53.3ms\n",
      "Speed: 1.0ms preprocess, 53.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cat, 1 dog, 1 bear, 1 potted plant, 54.5ms\n",
      "Speed: 0.0ms preprocess, 54.5ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cat, 1 dog, 2 potted plants, 55.8ms\n",
      "Speed: 1.0ms preprocess, 55.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cat, 1 bear, 1 potted plant, 53.7ms\n",
      "Speed: 0.0ms preprocess, 53.7ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bear, 2 potted plants, 56.4ms\n",
      "Speed: 0.0ms preprocess, 56.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 bear, 2 potted plants, 56.5ms\n",
      "Speed: 1.0ms preprocess, 56.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 dogs, 1 bear, 2 potted plants, 56.1ms\n",
      "Speed: 0.0ms preprocess, 56.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 dog, 1 bear, 2 potted plants, 56.4ms\n",
      "Speed: 0.0ms preprocess, 56.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 cat, 1 dog, 2 potted plants, 53.1ms\n",
      "Speed: 1.0ms preprocess, 53.1ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 cats, 1 bear, 2 potted plants, 55.8ms\n",
      "Speed: 1.0ms preprocess, 55.8ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cats, 2 potted plants, 56.5ms\n",
      "Speed: 0.0ms preprocess, 56.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cat, 2 potted plants, 54.7ms\n",
      "Speed: 1.0ms preprocess, 54.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "video_path = \"mixkit-paris-pedestrian-path-4349.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        results = model(frame)\n",
    "        # Visualize the results on the frame\n",
    "        # annotated_frame = results[0].plot()\n",
    "        for box in results[0].boxes:\n",
    "            if int(box.cls[0]) != 0:\n",
    "                continue\n",
    "            bbox = box.xyxy[0]\n",
    "            bbox = [int(x) for x in bbox]\n",
    "            cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"Pedestrian Detection\", frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T04:18:58.020930Z",
     "end_time": "2023-04-09T04:19:01.338245Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
